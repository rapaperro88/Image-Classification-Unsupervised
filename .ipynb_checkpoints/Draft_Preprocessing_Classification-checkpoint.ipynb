{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Display Some Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import functools\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we straighten ou images. Thanks to [Roman Odaisky](https://stackoverflow.com/users/21055/roman-odaisky)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def image_transpose_exif(im):\n",
    "    \"\"\"\n",
    "    Apply Image.transpose to ensure 0th row of pixels is at the visual\n",
    "    top of the image, and 0th column is the visual left-hand side.\n",
    "    Return the original image if unable to determine the orientation.\n",
    "\n",
    "    As per CIPA DC-008-2012, the orientation field contains an integer,\n",
    "    1 through 8. Other values are reserved.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    im: PIL.Image\n",
    "       The image to be rotated.\n",
    "    \"\"\"\n",
    "\n",
    "    exif_orientation_tag = 0x0112\n",
    "    exif_transpose_sequences = [                   # Val  0th row  0th col\n",
    "        [],                                        #  0    (reserved)\n",
    "        [],                                        #  1   top      left\n",
    "        [Image.FLIP_LEFT_RIGHT],                   #  2   top      right\n",
    "        [Image.ROTATE_180],                        #  3   bottom   right\n",
    "        [Image.FLIP_TOP_BOTTOM],                   #  4   bottom   left\n",
    "        [Image.FLIP_LEFT_RIGHT, Image.ROTATE_90],  #  5   left     top\n",
    "        [Image.ROTATE_270],                        #  6   right    top\n",
    "        [Image.FLIP_TOP_BOTTOM, Image.ROTATE_90],  #  7   right    bottom\n",
    "        [Image.ROTATE_90],                         #  8   left     bottom\n",
    "    ]\n",
    "\n",
    "    try:\n",
    "        seq = exif_transpose_sequences[im._getexif()[exif_orientation_tag]]\n",
    "    except Exception:\n",
    "        return im\n",
    "    else:\n",
    "        return functools.reduce(type(im).transpose, seq, im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# One folder with all images to sort :\n",
    "# “One Folder to rule them all, One Folder to find them, \n",
    "# One Folder to bring them all and in the darkness classify them.”  \n",
    "src_folder = \"C:\\data\\class_unsup\\poc2\"\n",
    "# src_folder = \"C:/data/unsamples\"\n",
    "\n",
    "def plot_some_images(src_folder, max_images=5):\n",
    "    # Set up a figure of an appropriate size\n",
    "    fig = plt.figure(figsize=(12, 16))\n",
    "    \n",
    "    img_num = 0\n",
    "    \n",
    "    # List of files\n",
    "    filenames = os.listdir(src_folder)\n",
    "    \n",
    "    n_col = 6\n",
    "    n_row = (len(filenames) // n_col) + 1\n",
    "    plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
    "    fig = plt.figure(figsize=(n_col*2 , n_row*2 ))\n",
    "    \n",
    "    for i, file in enumerate(filenames):\n",
    "        \n",
    "        imgFile = os.path.join(src_folder, file)\n",
    "        img = Image.open(imgFile)\n",
    "        img = image_transpose_exif(img)\n",
    "\n",
    "        plt.subplot(n_row, n_col, i + 1)\n",
    "        plt.imshow(img)\n",
    "        \n",
    "        img_num += 1\n",
    "         \n",
    "        if img_num == max_images : break\n",
    "    \n",
    "plot_some_images(src_folder, max_images=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following [beleidy/unsupervised-image-clustering](https://github.com/beleidy/unsupervised-image-clustering/blob/master/capstone.ipynb) capstone project, we will infer 3 different models to our images to ge the features present in our images. We then use PCA for dimension reduction purposes and finally we implement a clustering algorithm to make clusters of images by similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess and Normalize Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_image(src_image, size=(128,128), bg_color=\"white\"): \n",
    "    from PIL import Image, ImageOps \n",
    "    \n",
    "    # resize the image so the longest dimension matches our target size\n",
    "    src_image.thumbnail(size, Image.ANTIALIAS)\n",
    "    \n",
    "    # Create a new square background image\n",
    "    new_image = Image.new(\"RGB\", size, bg_color)\n",
    "    \n",
    "    # Paste the resized image into the center of the square background\n",
    "    new_image.paste(src_image, (int((size[0] - src_image.size[0]) / 2), int((size[1] - src_image.size[1]) / 2)))\n",
    "  \n",
    "    # return the resized image\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess_image(path_to_image, size, grey=True):\n",
    "        # open \n",
    "        img = Image.open(path_to_image)\n",
    "        \n",
    "        # straighten out :\n",
    "        img = image_transpose_exif(img)\n",
    "        \n",
    "        arr = np.array(img)\n",
    "        \n",
    "        # Padding with mean of color calculated on the image\n",
    "        r = int(np.floor(np.mean(arr[:,:,0])))\n",
    "        g = int(np.floor(np.mean(arr[:,:,1])))\n",
    "        b = int(np.floor(np.mean(arr[:,:,2])))\n",
    "        img = resize_image(img, size, bg_color=(r,g,b))\n",
    "        \n",
    "        if grey : \n",
    "            img = img.convert('L')\n",
    "            \n",
    "            # Convert to numpy arrays\n",
    "            img = np.array(img, dtype=np.float32)\n",
    "\n",
    "            # Simulate RGB needed to enter pretrained models\n",
    "            img = np.expand_dims(img, axis=2)\n",
    "            img = np.repeat(img, 3, -1)\n",
    "            \n",
    "        else :\n",
    "            # Convert to numpy arrays\n",
    "            img = np.array(img, dtype=np.float32)\n",
    "\n",
    "        # Normalise the images\n",
    "        img /= 255\n",
    "        return img\n",
    "\n",
    "def compile_images(src_folder, size=(128,128), max_images=1000, grey=True):\n",
    "    \n",
    "    # loop through the images\n",
    "    # Load .jpg only\n",
    "    filenames = [jpg for jpg in os.listdir(src_folder) if jpg.endswith(\".jpg\")]\n",
    "    \n",
    "    # Define empty arrays where we will store our images and labels\n",
    "    images = []\n",
    "            \n",
    "    for file in filenames[:max_images]:\n",
    "        imgFile = os.path.join(src_folder, file)\n",
    "        img = load_and_preprocess_image(imgFile, size, grey=grey)\n",
    "        \n",
    "        # Now we add it to our array\n",
    "        images.append(img)\n",
    "\n",
    "    return np.array(images, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = compile_images(src_folder, size=(256,256), max_images=100, grey=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Model and Make Predictions On Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YOLO v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from __future__ import division\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import cv2 \n",
    "# from util import *\n",
    "# from DNModel import net as Darknet\n",
    "import pandas as pd\n",
    "import random \n",
    "# import pickle as pkl\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COCO trained YOLOv3\n",
    "labelsPath = \"cfg/coco.names\"\n",
    "weightsPath = \"C:/data/class_unsup/yolov3.weights\"\n",
    "configPath = \"cfg/yolov3.cfg\"\n",
    "\n",
    "# Faces-Trained YOLOv3 (https://github.com/sthanhng/yoloface)\n",
    "# labelsPath = \"cfg/face.names\"\n",
    "# weightsPath = \"C:/data/class_unsup/yolov3-wider_16000.weights\"\n",
    "# configPath = \"cfg/yolov3-face.cfg\"\n",
    "\n",
    "# For bounding boxes\n",
    "LABELS = open(labelsPath).read().strip().split(\"\\n\")\n",
    "COLORS = np.random.randint(0, 255, size=(len(LABELS), 3), dtype=\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# load YOLO object detector pretrained on COCO dataset (80 classes)\n",
    "# and determine only the *output* layer names that we need from YOLO\n",
    "print(\"loading YOLO from disk...\")\n",
    "net = cv2.dnn.readNetFromDarknet(configPath, weightsPath)\n",
    "ln = net.getLayerNames()\n",
    "ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# POC\n",
    "for i in range(len(images[:6])):\n",
    "    image_sample = images[i]\n",
    "    plt.figure(figsize=(4,4))\n",
    "    plt.imshow(image_sample)\n",
    "    plt.show()\n",
    "    blob = cv2.dnn.blobFromImage(image_sample)\n",
    "\n",
    "    net.setInput(blob)\n",
    "    layerOutputs = net.forward(ln)\n",
    "\n",
    "    for detection in layerOutputs[1]:\n",
    "        scores = detection[5:] # 80 proba vector\n",
    "        classID = np.argmax(scores)\n",
    "        confidence = scores[classID]\n",
    "        if confidence > 0.1:\n",
    "            print(LABELS[classID])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLO IMPLEMENTATION\n",
    "\n",
    "\n",
    "# def flatten_yolo():\n",
    "\n",
    "flatten_set = []\n",
    "\n",
    "# Paths to model files\n",
    "labelsPath = \"cfg/coco.names\"\n",
    "weightsPath = \"C:/data/class_unsup/yolov3.weights\"\n",
    "configPath = \"cfg/yolov3.cfg\"\n",
    "\n",
    "# Load Model\n",
    "net = cv2.dnn.readNetFromDarknet(configPath, weightsPath)\n",
    "ln = net.getLayerNames()\n",
    "ln = [ln[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "# Generate probabilities vectors\n",
    "for image in images:\n",
    "    tmp = []\n",
    "    # Setup input \n",
    "    blob = cv2.dnn.blobFromImage(image)\n",
    "    net.setInput(blob)\n",
    "    # Infer\n",
    "    layerOutputs = net.forward(ln) \n",
    "    # Retrieve detections for the 768 yolo set : index=1\n",
    "    for detection in layerOutputs[1]:\n",
    "        scores = detection[5:] # 80 proba vector\n",
    "        tmp.extend(scores)\n",
    "        \n",
    "yolo_output = np.array(flatten_set)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# initialize our lists of detected bounding boxes, confidences,\n",
    "# and class IDs, respectively\n",
    "boxes = []\n",
    "confidences = []\n",
    "classIDs = []\n",
    "\n",
    "for image_ in images:\n",
    "# for i in range (1):\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(image_)\n",
    "    net.setInput(blob)\n",
    "    layerOutputs = net.forward(ln)\n",
    "    \n",
    "    for output in layerOutputs:\n",
    "\n",
    "        for detection in output:\n",
    "            scores = detection[5:]\n",
    "            classID = np.argmax(scores)\n",
    "            confidence = scores[classID]\n",
    "            \n",
    "        print(scores)\n",
    "        \n",
    "        if confidence > 0.5:\n",
    "            print(\"object  found\")\n",
    "            print(scores, \"\\n\", classID, \"\\n\", confidence)\n",
    "            # scale the bounding box coordinates back relative to\n",
    "            # the size of the image, keeping in mind that YOLO\n",
    "            # actually returns the center (x, y)-coordinates of\n",
    "            # the bounding box followed by the boxes' width and\n",
    "            # height\n",
    "            W = 128\n",
    "            H = 128\n",
    "            box = detection[0:4] * np.array([W, H, W, H])\n",
    "            (centerX, centerY, width, height) = box.astype(\"int\")\n",
    "            # use the center (x, y)-coordinates to derive the top\n",
    "            # and and left corner of the bounding box\n",
    "            x = int(centerX - (width / 2))\n",
    "            y = int(centerY - (height / 2))\n",
    "            # update our list of bounding box coordinates,\n",
    "            # confidences, and class IDs\n",
    "            boxes.append([x, y, int(width), int(height)])\n",
    "            confidences.append(float(confidence))\n",
    "            classIDs.append(classID)\n",
    "\n",
    "        # apply non-maxima suppression to suppress weak, overlapping\n",
    "            # bounding boxes\n",
    "            idxs = cv2.dnn.NMSBoxes(boxes, confidences, args[\"confidence\"],\n",
    "                args[\"threshold\"])\n",
    "            # ensure at least one detection exists\n",
    "            if len(idxs) > 0:\n",
    "                # loop over the indexes we are keeping\n",
    "                for i in idxs.flatten():\n",
    "                    # extract the bounding box coordinates\n",
    "                    (x, y) = (boxes[i][0], boxes[i][1])\n",
    "                    (w, h) = (boxes[i][2], boxes[i][3])\n",
    "                    # draw a bounding box rectangle and label on the frame\n",
    "                    color = [int(c) for c in COLORS[classIDs[i]]]\n",
    "                    cv2.rectangle(frame, (x, y), (x + w, y + h), \"black\", 2)\n",
    "                    text = \"{}: {:.4f}\".format(LABELS[classIDs[i]],\n",
    "                        confidences[i])\n",
    "                    cv2.putText(img_1, text, (x, y - 5),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import spectral_clustering\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "model = resnet50_model\n",
    "inp = images[4]                                          # input placeholder\n",
    "outputs = [layer.output for layer in model.layers]          # all layer outputs\n",
    "functors = [K.function([inp, K.learning_phase()], [out]) for out in outputs]    # evaluation functions\n",
    "\n",
    "# Testing\n",
    "test = np.random.random(input_shape)[np.newaxis,...]\n",
    "layer_outs = [func([test, 1.]) for func in functors]\n",
    "print (layer_outs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "inputs = tf.keras.Input(shape=(3,))\n",
    "x = tf.keras.layers.Dense(4, activation=tf.nn.relu)(inputs)\n",
    "outputs = tf.keras.layers.Dense(5, activation=tf.nn.softmax)(x)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# images[3:5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (resnet50_model.predict(images[3:5])[1, :, :, :]).shape\n",
    "prds = resnet50_model.predict(images[3:5])\n",
    "prds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot all 64 maps in an 8x8 squares\n",
    "square = 10\n",
    "ix = 1\n",
    "for _ in range(square):\n",
    "    for _ in range(square):\n",
    "        # specify subplot and turn of axis\n",
    "        ax = plt.subplot(square, square, ix)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        # plot filter channel in grayscale\n",
    "        plt.imshow(prds[1, :, :, ix-1], cmap='gray')\n",
    "        ix += 1\n",
    "# show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(128,128,3)\n",
    "\n",
    "resnet50_model = keras.applications.resnet50.ResNet50(include_top=False, weights=\"imagenet\", input_shape=input_shape)\n",
    "vgg16_model = keras.applications.vgg16.VGG16(include_top=False, weights=\"imagenet\", input_shape=input_shape)\n",
    "vgg19_model = keras.applications.vgg19.VGG19(include_top=False, weights=\"imagenet\", input_shape=input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50_model.layers[-1].output\n",
    "# outputs = [layer.output for layer in model.layers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_output(covnet_model, raw_images):\n",
    "    # Infer the model on raw data\n",
    "    pred = covnet_model.predict(raw_images)\n",
    "    # Flatten the prediction array\n",
    "    flat = pred.reshape(raw_images.shape[0], -1)\n",
    "    \n",
    "    return pred, flat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_clusters = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "resnet50_output = flatten_output(resnet50_model, images)\n",
    "print(\"ResNet50 flattened output has {} features\".format(resnet50_output.shape[1]))\n",
    "\n",
    "vgg19_output = flatten_output(vgg19_model, images)\n",
    "print(\"VGG19 flattened output has {} features\".format(vgg19_output.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that creates a PCA instance, fits it to the data and returns the instance\n",
    "def create_fit_PCA(data, n_components=None):\n",
    "    p = PCA(n_components=n_components, random_state=728)\n",
    "    p.fit(data)\n",
    "    return p\n",
    "\n",
    "# Function to plot the cumulative explained variance of PCA components\n",
    "def pca_cumsum_plot(pca):\n",
    "    plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "    plt.xlabel('number of components')\n",
    "    plt.ylabel('cumulative explained variance')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create PCA instances for each output\n",
    "vgg19_pca = create_fit_PCA(vgg19_output)\n",
    "resnet50_pca = create_fit_PCA(resnet50_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_cumsum_plot(vgg19_pca)\n",
    "pca_cumsum_plot(resnet50_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19_output_pca = vgg19_pca.transform(vgg19_output)\n",
    "resnet50_output_pca = resnet50_pca.transform(resnet50_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPECTRAL CLUSTERING\n",
    "\n",
    "\n",
    "\n",
    "# def create_train_spectral(data, number_of_clusters=nb_clusters):\n",
    "#     s = spectral_clustering(data, n_clusters=nb_clusters, eigen_solver='arpack')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KMEANS\n",
    "def create_train_kmeans(data, number_of_clusters=nb_clusters):\n",
    "    \n",
    "    k = KMeans(n_clusters=number_of_clusters, random_state=728)\n",
    "\n",
    "    # Let's do some timings to see how long it takes to train.\n",
    "    start = time.time()\n",
    "\n",
    "    # Train it up\n",
    "    k.fit(data)\n",
    "\n",
    "    # Stop the timing \n",
    "    end = time.time()\n",
    "\n",
    "    # And see how long that took\n",
    "    print(\"Training took {} seconds\".format(end-start))\n",
    "    \n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAUSSIAN MIXTURE\n",
    "def create_train_gmm(data, number_of_clusters=nb_clusters):\n",
    "    g = GaussianMixture(n_components=number_of_clusters,\n",
    "                        covariance_type=\"full\", \n",
    "                        random_state=728,\n",
    "                        n_init=5,\n",
    "                        init_params='random',\n",
    "                       )\n",
    "    \n",
    "    start=time.time()\n",
    "    g.fit(data)\n",
    "    end=time.time()\n",
    "    \n",
    "    print(\"Training took {} seconds\".format(end-start))\n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def group_and_plot(src_folder, clusters, size=(128,128), plot=True, grey=False):\n",
    "    \n",
    "    # Dict for sorted filenames\n",
    "    dico = {}\n",
    "    for i in range(nb_clusters):\n",
    "        dico[i] = []\n",
    "        \n",
    "    # All filenames    \n",
    "    filenames = [jpg for jpg in os.listdir(src_folder) if jpg.endswith(\".jpg\")]\n",
    "\n",
    "    # Sort filenames\n",
    "    for i, clu in enumerate(clusters):\n",
    "        dico[clu].append(filenames[i])\n",
    "    \n",
    "    # option: plot group of images\n",
    "    if plot :        \n",
    "        for clu in dico.keys():            \n",
    "            print(\"************************************************\")\n",
    "            print(f\"******************* group {clu} ********************\")\n",
    "            print(\"************************************************\")\n",
    "            \n",
    "            n_col = 6\n",
    "            n_row = (len(dico[clu]) // n_col) + 1\n",
    "            plt.subplots_adjust(bottom=0, left=.01, right=.99, top=.90, hspace=.35)\n",
    "            fig = plt.figure(figsize=(n_col*3 , n_row*3 ))\n",
    "            \n",
    "            for i, file in enumerate(dico[clu]):\n",
    "                imgFile = os.path.join(src_folder, file)\n",
    "                \n",
    "                img = load_and_preprocess_image(imgFile, size, grey)\n",
    "                                \n",
    "                plt.subplot(n_row, n_col, i + 1)\n",
    "                plt.imshow(img)\n",
    "\n",
    "            plt.show()\n",
    "                \n",
    "    return dico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n FIT DATA \\n\")\n",
    "\n",
    "# Here we create and fit a KMeans model with the PCA outputs\n",
    "print(\"\\n KMeans (PCA): \\n\")\n",
    "\n",
    "K_vgg19_pca = create_train_kmeans(vgg19_output_pca)\n",
    "K_resnet50_pca = create_train_kmeans(resnet50_output_pca)\n",
    "\n",
    "# Same for Gaussian Model\n",
    "print(\"\\n GMM (PCA): \\n\")\n",
    "\n",
    "G_vgg19_pca = create_train_gmm(vgg19_output_pca)\n",
    "G_resnet50_pca = create_train_gmm(resnet50_output_pca)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# PREDICTIONS\n",
    "print(\"CLUSTERING...\")\n",
    "# KMeans with PCA outputs\n",
    "k_vgg19_pred_pca = K_vgg19_pca.predict(vgg19_output_pca)\n",
    "k_resnet50_pred_pca = K_resnet50_pca.predict(resnet50_output_pca)\n",
    "\n",
    "# Gaussian Mixture with PCA outputs\n",
    "g_resnet50_pred_pca = G_resnet50_pca.predict(resnet50_output_pca)\n",
    "g_vgg19_pred_pca = G_vgg19_pca.predict(vgg19_output_pca)\n",
    "\n",
    "print(\"CLUSTER DATA GENERATED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Yolo raw output\n",
    "plt.figure(figsize=(15,3))\n",
    "plt.scatter(yolo_output[)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.scatter(yolo_output_scaled[0], \n",
    "            yolo_output_scaled[1], \n",
    "            marker='.', \n",
    "#             s=10 \n",
    "           )\n",
    "# plt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "yolo_output_scaled = scaler.fit_transform(yolo_output)\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "db = DBSCAN (eps=0.2,min_samples=2)\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "mms = MinMaxScaler()\n",
    "yolo_mms = mms.fit_transform(yolo_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLO clustering\n",
    "yolo_pca = create_fit_PCA(yolo_output, n_components=15)\n",
    "\n",
    "pca_cumsum_plot(yolo_pca)\n",
    "\n",
    "yolo_output_pca = yolo_pca.transform(yolo_output)\n",
    "\n",
    "K_yolo_pca = create_train_kmeans(yolo_output)\n",
    "k_yolo_pred_pca = K_yolo_pca.predict(yolo_output)\n",
    "\n",
    "\n",
    "GM_yolo_pca = create_train_kmeans(yolo_output)\n",
    "gm_yolo_pred_pca = GM_yolo_pca.predict(yolo_output)\n",
    "\n",
    "agglo_cluster = AgglomerativeClustering(n_clusters=nb_clusters).fit(yolo_output)\n",
    "agglo_pred = agglo_cluster.labels_\n",
    "\n",
    "fit = db.fit(yolo_output_scaled)\n",
    "db_pred = fit.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gm_yolo_pred_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_size = (64,64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Best result\n",
    "\n",
    "**vgg19** pretrained model followed by **kmeans clustering** achieved some sort of clustering : \n",
    "* group 0 : closed places (indoors or dark)\n",
    "* group 1 : open places (outdoors, landscapes)\n",
    "* group 2 : people (mostly pictures featuring people)\n",
    "\n",
    "However, this is a subjective apreciation. An improvement would consist in exploring object identification techniques like yolo. And have a clustring method with information as objects present in the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gm_yolo_pred_pca_sorted_filenames = group_and_plot(src_folder, gm_yolo_pred_pca, size=display_size, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "k_yolo_pred_pca_sorted_filenames = group_and_plot(src_folder, k_yolo_pred_pca, size=display_size, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "k_vgg19_pred_pca_sorted_filenames = group_and_plot(src_folder, k_vgg19_pred_pca, size=display_size, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_resnet50_pred_pca_sorted_filenames = group_and_plot(src_folder, k_resnet50_pred_pca, size=display_size, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_resnet50_pred_pca_filenames = group_and_plot(src_folder, g_resnet50_pred_pca, size=display_size, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_vgg19_pred_pca_filenames = group_and_plot(src_folder, g_vgg19_pred_pca, size=display_size, plot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
